{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf114e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Riker Wachtler\n",
      "11 December 2023\n",
      "DL Final Project\n",
      "https://github.com/RikerW/final-dl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Riker Wachtler\n",
    "11 December 2023\n",
    "DL Final Project\n",
    "https://github.com/RikerW/final-dl\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64d04477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the completed version of my final project. I left short comments for each thing I'm doing - but in short,\n",
      "it's doing some pre-processing stuff as EDA and then getting into it.\n",
      "\n",
      "This implements a mediocre language translation model (english to spanish) using LTSMs, plus an encoder and decoder.\n",
      "\n",
      "I'll be honest - I wrote most of this, then looked back and said oh whoops, I need an AUTO-encoder for criteria 1, not just an encoder. \n",
      "However, I think should more than count for \"Deep Learning Models\" - the encoders are definitely a form of ANN?\n",
      "They're just feed forward networks, unless I'm mistaken.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "This is the completed version of my final project. I left short comments for each thing I'm doing - but in short,\n",
    "it's doing some pre-processing stuff as EDA and then getting into it.\n",
    "\n",
    "This implements a mediocre language translation model (english to spanish) using LTSMs, plus an encoder and decoder.\n",
    "\n",
    "I'll be honest - I wrote most of this, then looked back and said oh whoops, I need an AUTO-encoder for criteria 1, not just an encoder. \n",
    "However, I think should more than count for \"Deep Learning Models\" - the encoders are definitely a form of ANN?\n",
    "They're just feed forward networks, unless I'm mistaken.\n",
    "\n",
    "The callbacks I added are just logs, but hopefully that suffices. Anyway, that's about it. This is a deceptively short project.\n",
    "I reverse engineered a substantial portion from an example from Keras for english->french, which is where I got the data from,\n",
    "but I wrote all of this code myself.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a03a980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riker\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, tensorflow as tf, seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM, Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d037179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/spa.txt\", header=None, delimiter=r\"\\t+\")\n",
    "df = df.rename(columns={0: 'english', 1: 'spanish', 2: 'attribution'})\n",
    "df.dropna(0)\n",
    "\n",
    "# thanks for attributing it! but we don't need this information for our purposes\n",
    "del df[\"attribution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c2fa1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Ve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vete.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Váyase.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hola.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Run!</td>\n",
       "      <td>¡Corre!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Run!</td>\n",
       "      <td>¡Corran!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Run!</td>\n",
       "      <td>¡Huye!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Run!</td>\n",
       "      <td>¡Corra!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Run!</td>\n",
       "      <td>¡Corred!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english   spanish\n",
       "0     Go.       Ve.\n",
       "1     Go.     Vete.\n",
       "2     Go.     Vaya.\n",
       "3     Go.   Váyase.\n",
       "4     Hi.     Hola.\n",
       "5    Run!   ¡Corre!\n",
       "6    Run!  ¡Corran!\n",
       "7    Run!    ¡Huye!\n",
       "8    Run!   ¡Corra!\n",
       "9    Run!  ¡Corred!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df9508a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>141370</td>\n",
       "      <td>141370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>119661</td>\n",
       "      <td>132831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>You can put it there.</td>\n",
       "      <td>Estoy quebrado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      english          spanish\n",
       "count                  141370           141370\n",
       "unique                 119661           132831\n",
       "top     You can put it there.  Estoy quebrado.\n",
       "freq                       68               13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e75ab13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 141370 entries, 0 to 141369\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   english  141370 non-null  object\n",
      " 1   spanish  141370 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edba4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is at the top so I can find it again easily. this numbers are shorter than they should be all things considered,\n",
    "# because I don't want to spend years re-training models. num_samples should be 10k and epochs 100 for real use, probably.\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "latent_dim = 256\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c790eb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 [' ', '!', '$', \"'\", ',', '.', '0', '1', '3', '5', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "39 [' ', '!', '\"', ',', '.', '0', '1', '3', '5', '7', '8', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '¡', '¿', 'Á', 'É', 'Ó', 'Ú', 'á', 'é', 'í', 'ñ', 'ó', 'ú', 'ü']\n"
     ]
    }
   ],
   "source": [
    "# set up token counts n sequence lengths for encoder (eng), decoder (spa)\n",
    "# all things considered this really just preps everything to OHE some stuff, and gives us useful sizes for later\n",
    "\n",
    "eng = df.filter([\"english\"], axis=1)\n",
    "eng = eng[0:3000]\n",
    "\n",
    "spa = df.filter([\"spanish\"], axis=1)\n",
    "spa = spa[0:3000]\n",
    "\n",
    "eng_chars = sorted(list(Counter(''.join(eng.unstack().values)).keys()))\n",
    "spa_chars = sorted(list(Counter(''.join(spa.unstack().values)).keys()))\n",
    "\n",
    "num_eng_chars = len(eng_chars)\n",
    "num_spa_chars = len(spa_chars)\n",
    "\n",
    "max_eng_len = eng.english.map(len).max()+1\n",
    "max_spa_len = spa.spanish.map(len).max()+1\n",
    "\n",
    "eng_index = dict([(char, i) for i, char in enumerate(eng_chars)])\n",
    "spa_index = dict([(char, i) for i, char in enumerate(spa_chars)])\n",
    "\n",
    "print(max_eng_len, eng_chars)\n",
    "print(max_spa_len, spa_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "953faf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "# oh yeah, we truncated this to 3000 instead of ~14000 because I don't like generating obscenely large one-hot vectors (jupyter said 18.7 GB?)\n",
    "total_length = len(eng)\n",
    "assert total_length == len(spa)\n",
    "print(total_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "164d4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up encoder inputs - we're one-hot encoding them, with the code below :)\n",
    "encoder_input  = np.zeros((total_length, max_eng_len, num_eng_chars), dtype='float32')\n",
    "decoder_input  = np.zeros((total_length, max_spa_len, num_spa_chars), dtype='float32')\n",
    "decoder_target = np.zeros((total_length, max_spa_len, num_spa_chars), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "890f2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE the suckers - stagger the decoder target by one character, since we're working on predicting the next one lol\n",
    "\n",
    "for i in range(total_length):\n",
    "    cur_eng = eng.english[i]\n",
    "    cur_spa = spa.spanish[i]\n",
    "    \n",
    "    for j in range(len(cur_eng)):\n",
    "        encoder_input[i, j, eng_index[cur_eng[j]]] = 1\n",
    "    encoder_input[i, j+1, eng_index[' ']] = 1\n",
    "    \n",
    "    for j in range(len(cur_spa)):\n",
    "        decoder_input[i, j, spa_index[cur_spa[j]]] = 1\n",
    "        if j > 0:\n",
    "            decoder_target[i, j-1, spa_index[cur_spa[j]]] = 1\n",
    "    decoder_input[i, j+1, spa_index[' ']] = 1\n",
    "    decoder_target[i, j, spa_index[' ']] = 1\n",
    "    decoder_target[i, j+1, spa_index[' ']] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ced0c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder model - input, LTSM, into a model from the states. not very complicated\n",
    "eng_inp = Input(shape=(None, num_eng_chars))\n",
    "eng_enc = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "eng_out, estate_h, estate_c = eng_enc(eng_inp)\n",
    "\n",
    "eng_states = [estate_h, estate_c]\n",
    "\n",
    "eng_model = Model(eng_inp, eng_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd73c018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm')>,\n",
       "  <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm')>],\n",
       " <keras.src.engine.functional.Functional at 0x152db8429d0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_states, eng_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "781d5b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a decoder model - more complicated. you need to an LTSM with states like normal,\n",
    "# but we also need to make it fancier since this one needs to actually set it up to go once to set up our starting state \n",
    "spa_inp = Input(shape=(None, num_spa_chars))\n",
    "spa_dec = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "spa_out, sstate_h, sstate_c = spa_dec(spa_inp, initial_state=eng_states)\n",
    "\n",
    "spa_h_inp = Input(shape=(latent_dim,))\n",
    "spa_c_inp = Input(shape=(latent_dim,))\n",
    "spa_inps = [spa_h_inp, spa_c_inp]\n",
    "\n",
    "spa_out, sstate_h, sstate_c = spa_dec(spa_inp, initial_state=spa_inps)\n",
    "spa_states = [sstate_h, sstate_c]\n",
    "\n",
    "spa_dense = Dense(num_spa_chars, activation='softmax')\n",
    "spa_out = spa_dense(spa_out)\n",
    "spa_model = Model([spa_inp] + spa_inps, [spa_out] + spa_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a51612a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm_1')>,\n",
       "  <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm_1')>],\n",
       " <keras.src.engine.functional.Functional at 0x152dc358130>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spa_states, spa_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b1defdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "38/38 [==============================] - 8s 132ms/step - loss: 1.2092 - accuracy: 0.7157 - val_loss: 1.1955 - val_accuracy: 0.7089\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 4s 115ms/step - loss: 1.0698 - accuracy: 0.7398 - val_loss: 1.1877 - val_accuracy: 0.7088\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 4s 116ms/step - loss: 1.0601 - accuracy: 0.7405 - val_loss: 1.1912 - val_accuracy: 0.7088\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 4s 112ms/step - loss: 1.0593 - accuracy: 0.7402 - val_loss: 1.1937 - val_accuracy: 0.7088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15304e73f10>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's a demo that shows i know how to use logs\n",
    "\n",
    "nspa_inp = Input(shape=(None, num_spa_chars))\n",
    "neng_inp = Input(shape=(None, num_eng_chars))\n",
    "neng_enc = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "neng_out, nestate_h, nestate_c = neng_enc(neng_inp)\n",
    "\n",
    "neng_states = [nestate_h, nestate_c]\n",
    "\n",
    "nspa_dec = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "nspa_out, _, _ = nspa_dec(nspa_inp, initial_state=neng_states)\n",
    "nspa_out = Dense(num_spa_chars, activation='softmax')(nspa_out)\n",
    "\n",
    "nmodel = Model([neng_inp, nspa_inp], nspa_out)\n",
    "\n",
    "# Generic callbacks to use\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{accuracy:.2f}.h5'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "# Run training\n",
    "nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "nmodel.fit([encoder_input, decoder_input], decoder_target, batch_size=batch_size, epochs=epochs, validation_split=0.2, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e66c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually try to predict something :)\n",
    "\n",
    "rev_spa_index = {v: k for k, v in spa_index.items()}\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states = eng_model.predict(input_seq)\n",
    "\n",
    "    target = np.zeros((1, 1, num_spa_chars))\n",
    "    target[0, 0, spa_index['\\t']] = 1.\n",
    "\n",
    "    out = ''\n",
    "    while True:\n",
    "        # predict some tokens baby\n",
    "        out_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # actually add a token to our output :)\n",
    "        out_token = np.argmax(out_tokens[0, -1, :])\n",
    "        out_char = rev_spa_index[out_token]\n",
    "        out += out_cha\n",
    "\n",
    "        # if our decoder thinks we're done, or we hit the len cap, end it\n",
    "        if (out_cha == '\\n' or len(out) > max_spa_len):\n",
    "            break;\n",
    "\n",
    "        # otherwise, keep us going and update our target + state for the next loop\n",
    "        target = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target[0, 0, sampled_token_index] = 1.\n",
    "        states = [h, c]\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8e13706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "-\n",
      "Input sentence: Exhale.\n",
      "Decoded sentence: Espírad..\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "pid = random.randint(0, 100)\n",
    "input_seq = encoder_input[pid]\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('-')\n",
    "print('Input sentence:', eng.english[pid])\n",
    "print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "289b9cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Overall takeaways - it's actually remarkably involved to do what I thought wouldn't take very long at first.\n",
      "Not super hard, but certainly complex. We worked with similar LTSM stuff - but pre-loaded models. Combining them with writing my own encoders and decoders is VERY finicky as well.\n",
      "I'm pretty sure despite re-running this repeatedly there's at least one odd variable name that breaks things because of how many times I rewrote this.\n",
      "\n",
      "I definitely have more of an appreciation for machine translation. Also, mine sucked a little - I re-ran it a couple times and this is more or less what it outputs 70% of the time, I think i'm off by one for my OHE unfortunately.\n",
      "Nonetheless, definitely an interesting project.\n",
      "\n",
      "-- Riker\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "\n",
    "Overall takeaways - it's actually remarkably involved to do what I thought wouldn't take very long at first.\n",
    "Not super hard, but certainly complex. We worked with similar LTSM stuff - but pre-loaded models. Combining them with writing my own encoders and decoders is VERY finicky as well.\n",
    "I'm pretty sure despite re-running this repeatedly there's at least one odd variable name that breaks things because of how many times I rewrote this.\n",
    "\n",
    "I definitely have more of an appreciation for machine translation. Also, mine sucked a little - I re-ran it a couple times and this is more or less what it outputs 70% of the time, I think i'm off by one for my OHE unfortunately.\n",
    "Nonetheless, definitely an interesting project.\n",
    "\n",
    "-- Riker\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96bce44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
